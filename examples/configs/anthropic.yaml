# Anthropic Claude Configuration
# This configuration uses Anthropic's Claude models for the AI agent

llm:
  # Provider name - "anthropic" for Claude models
  provider: anthropic
  
  # Model to use - options include:
  # - claude-3-opus-20240229: Most capable Claude model
  # - claude-3-sonnet-20240229: Balanced performance and speed
  # - claude-3-haiku-20240307: Fastest and most cost-effective
  model: claude-3-sonnet-20240229
  
  # API key for authentication
  # Use environment variable for security: ${ANTHROPIC_API_KEY}
  # Or set directly (not recommended for production): sk-ant-...
  api_key: ${ANTHROPIC_API_KEY}

  # Base URL for the Anthropic API
  base_url: https://api.anthropic.com/v1
  
  # Temperature controls randomness (0.0 to 1.0 for Claude)
  # - Lower values (0.0-0.3): More focused and deterministic
  # - Medium values (0.4-0.7): Balanced creativity
  # - Higher values (0.8-1.0): More creative and varied
  temperature: 0.7
  
  # Maximum tokens in the response
  # Claude models support up to 4096 output tokens
  max_tokens: 2000

memory:
  # Maximum number of messages to retain in conversation history
  # Older messages are dropped when this limit is reached
  max_messages: 50
  
  # Token budget for context window
  # Claude 3 models have a 200K context window
  # This setting controls how much history to include
  token_budget: 8000

# List of enabled tools (optional)
# Available tools: calculator, file_reader, web_search
tools:
  - calculator
  - file_reader

# List of enabled guardrails (optional)
# Available guardrails: file_path, rate_limit
guardrails:
  - file_path
